{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questo è un testo, non è da codificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamo i vari import che ci serviranno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "#Forzare l'utilizzo di tensorflow 1\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import helper\n",
    "from glob import glob\n",
    "import pickle as pkl\n",
    "import scipy.misc\n",
    "\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "do_preprocess = False\n",
    "from_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resized_dir = \"./resized_images\"# Resized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiunte le funzioni utili, passo a esplorare i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, columns, width, height, max_number = 3):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image_path in enumerate(images):\n",
    "        if (i <= max_number):\n",
    "            plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "            img = cv2.imread(image_path, 0)\n",
    "            plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo qualche immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(os.path.join(data_resized_dir,'*.jpg'))\n",
    "columns = 3\n",
    "\n",
    "# questo serve per mostrare qualche immagine\n",
    "#show_images(images = images, columns = 3, width = 128, height = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the version of Tensorflow and access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Taken from Udacity face generator project\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modello Input funzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(real_dim, z_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param real_dim: tuple containing width, height and channels\n",
    "    :param z_dim: The dimension of Z\n",
    "    :return: Tuple of (tensor of real input images, tensor of z data, learning rate G, learning rate D)\n",
    "    \"\"\"\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
    "    learning_rate_G = tf.placeholder(tf.float32, name=\"learning_rate_G\")\n",
    "    learning_rate_D = tf.placeholder(tf.float32, name=\"learning_rate_D\")\n",
    "    \n",
    "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, output_channel_dim, is_train=True):\n",
    "    ''' Build the generator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        z : Input tensor for the generator\n",
    "        output_channel_dim : Shape of the generator output\n",
    "        n_units : Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out: \n",
    "    '''\n",
    "    with tf.variable_scope(\"generator\", reuse= not is_train):\n",
    "        \n",
    "        # First FC layer --> 8x8x1024\n",
    "        fc1 = tf.layers.dense(z, 8*8*1024)\n",
    "        \n",
    "        # Reshape it\n",
    "        fc1 = tf.reshape(fc1, (-1, 8, 8, 1024))\n",
    "        \n",
    "        # Leaky ReLU\n",
    "        fc1 = tf.nn.leaky_relu(fc1, alpha=alpha)\n",
    "\n",
    "        \n",
    "        # Transposed conv 1 --> BatchNorm --> LeakyReLU\n",
    "        # 8x8x1024 --> 16x16x512\n",
    "        trans_conv1 = tf.layers.conv2d_transpose(inputs = fc1,\n",
    "                                  filters = 512,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv1\")\n",
    "        \n",
    "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1, training=is_train, epsilon=1e-5, name=\"batch_trans_conv1\")\n",
    "       \n",
    "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1, alpha=alpha, name=\"trans_conv1_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 2 --> BatchNorm --> LeakyReLU\n",
    "        # 16x16x512 --> 32x32x256\n",
    "        trans_conv2 = tf.layers.conv2d_transpose(inputs = trans_conv1_out,\n",
    "                                  filters = 256,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv2\")\n",
    "        \n",
    "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2, training=is_train, epsilon=1e-5, name=\"batch_trans_conv2\")\n",
    "       \n",
    "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2, alpha=alpha, name=\"trans_conv2_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 3 --> BatchNorm --> LeakyReLU\n",
    "        # 32x32x256 --> 64x64x128\n",
    "        trans_conv3 = tf.layers.conv2d_transpose(inputs = trans_conv2_out,\n",
    "                                  filters = 128,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv3\")\n",
    "        \n",
    "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3, training=is_train, epsilon=1e-5, name=\"batch_trans_conv3\")\n",
    "       \n",
    "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3, alpha=alpha, name=\"trans_conv3_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 4 --> BatchNorm --> LeakyReLU\n",
    "        # 64x64x128 --> 128x128x64\n",
    "        trans_conv4 = tf.layers.conv2d_transpose(inputs = trans_conv3_out,\n",
    "                                  filters = 64,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv4\")\n",
    "        \n",
    "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4, training=is_train, epsilon=1e-5, name=\"batch_trans_conv4\")\n",
    "       \n",
    "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4, alpha=alpha, name=\"trans_conv4_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 5 --> tanh\n",
    "        # 128x128x64 --> 128x128x3\n",
    "        logits = tf.layers.conv2d_transpose(inputs = trans_conv4_out,\n",
    "                                  filters = 3,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [1,1],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"logits\")\n",
    "         \n",
    "        out = tf.tanh(logits, name=\"out\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, is_reuse=False, alpha = 0.2):\n",
    "    ''' Build the discriminator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Input tensor for the discriminator\n",
    "        n_units: Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out, logits: \n",
    "    '''\n",
    "    with tf.variable_scope(\"discriminator\", reuse = is_reuse): \n",
    "        \n",
    "        # Input layer 128*128*3 --> 64x64x64\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv1 = tf.layers.conv2d(inputs = x,\n",
    "                                filters = 64,\n",
    "                                kernel_size = [5,5],\n",
    "                                strides = [2,2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv1')\n",
    "        \n",
    "        batch_norm1 = tf.layers.batch_normalization(conv1,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                     name = 'batch_norm1')\n",
    "\n",
    "        conv1_out = tf.nn.leaky_relu(batch_norm1, alpha=alpha, name=\"conv1_out\")\n",
    "        \n",
    "        \n",
    "        # 64x64x64--> 32x32x128\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv2 = tf.layers.conv2d(inputs = conv1_out,\n",
    "                                filters = 128,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv2')\n",
    "        \n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                     name = 'batch_norm2')\n",
    "        \n",
    "        conv2_out = tf.nn.leaky_relu(batch_norm2, alpha=alpha, name=\"conv2_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 32x32x128 --> 16x16x256\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv3 = tf.layers.conv2d(inputs = conv2_out,\n",
    "                                filters = 256,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv3')\n",
    "        \n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm3')\n",
    "        \n",
    "        conv3_out = tf.nn.leaky_relu(batch_norm3, alpha=alpha, name=\"conv3_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 16x16x256 --> 16x16x512\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv4 = tf.layers.conv2d(inputs = conv3_out,\n",
    "                                filters = 512,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [1, 1],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv4')\n",
    "        \n",
    "        batch_norm4 = tf.layers.batch_normalization(conv4,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm4')\n",
    "        \n",
    "        conv4_out = tf.nn.leaky_relu(batch_norm4, alpha=alpha, name=\"conv4_out\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # 16x16x512 --> 8x8x1024\n",
    "        # Conv --> BatchNorm --> LeakyReLU   \n",
    "        conv5 = tf.layers.conv2d(inputs = conv4_out,\n",
    "                                filters = 1024,\n",
    "                                kernel_size = [5, 5],\n",
    "                                strides = [2, 2],\n",
    "                                padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name='conv5')\n",
    "        \n",
    "        batch_norm5 = tf.layers.batch_normalization(conv5,\n",
    "                                                   training = True,\n",
    "                                                   epsilon = 1e-5,\n",
    "                                                name = 'batch_norm5')\n",
    "        \n",
    "        conv5_out = tf.nn.leaky_relu(batch_norm5, alpha=alpha, name=\"conv5_out\")\n",
    "\n",
    "         \n",
    "        # Flatten it\n",
    "        flatten = tf.reshape(conv5_out, (-1, 8*8*1024))\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(inputs = flatten,\n",
    "                                units = 1,\n",
    "                                activation = None)\n",
    "        \n",
    "        \n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo Perdita del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, output_channel_dim, alpha):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    # Generator network here\n",
    "    g_model = generator(input_z, output_channel_dim)   \n",
    "    # g_model is the generator output\n",
    "    \n",
    "    # Discriminator network here\n",
    "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model,is_reuse=True, alpha=alpha)\n",
    "    \n",
    "    # Calculate losses\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n",
    "                                                          labels=tf.ones_like(d_model_real)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n",
    "                                                          labels=tf.zeros_like(d_model_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    g_loss = tf.reduce_mean(\n",
    "             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                     labels=tf.ones_like(d_model_fake)))\n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ottimizzatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"    \n",
    "    # Get the trainable_variables, split into G and D parts\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    # Generator update\n",
    "    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n",
    "    \n",
    "    # Optimizers\n",
    "    with tf.control_dependencies(gen_updates):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate=lr_D, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate=lr_G, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        \n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode, image_path, save, show):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    :param image_path: Path to save the image\n",
    "    \"\"\"\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "    \n",
    "    if save == True:\n",
    "        # Save image\n",
    "        images_grid.save(image_path, 'JPEG')\n",
    "    \n",
    "    if show == True:\n",
    "        plt.imshow(images_grid, cmap=cmap)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate_D, learning_rate_G, beta1, get_batches, data_shape, data_image_mode, alpha):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    :param epoch_count: Number of epochs\n",
    "    :param batch_size: Batch Size\n",
    "    :param z_dim: Z dimension\n",
    "    :param learning_rate: Learning Rate\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :param get_batches: Function to get batches\n",
    "    :param data_shape: Shape of the data\n",
    "    :param data_image_mode: The image mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    # Create our input placeholders\n",
    "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], z_dim)\n",
    "        \n",
    "    # Losses\n",
    "    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3], alpha)\n",
    "    \n",
    "    # Optimizers\n",
    "    d_opt, g_opt = model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    print('Comincio training')\n",
    "    \n",
    "    version = \"firstTrain\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Saver\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        num_epoch = 0\n",
    "        \n",
    "        try:\n",
    "            saver.restore(sess, \"./models/model.ckpt\")\n",
    "        except IOError:\n",
    "            print(\"File not accessible\")\n",
    "        \n",
    "        if from_checkpoint == True:\n",
    "            saver.restore(sess, \"./models/model.ckpt\")\n",
    "            \n",
    "            show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False)\n",
    "            \n",
    "        else:\n",
    "            for epoch_i in range(epoch_count):        \n",
    "                num_epoch += 1\n",
    "\n",
    "                if num_epoch % 5 == 0:\n",
    "\n",
    "                    # Save model every 5 epochs\n",
    "                    #if not os.path.exists(\"models/\" + version):\n",
    "                    #    os.makedirs(\"models/\" + version)\n",
    "                    save_path = saver.save(sess, \"./models/model.ckpt\")\n",
    "                    \n",
    "\n",
    "                for batch_images in get_batches(batch_size):\n",
    "                    # Random noise\n",
    "                    batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "                    # Run optimizers\n",
    "                    _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: learning_rate_D})\n",
    "                    _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: learning_rate_G})\n",
    "\n",
    "                    if i % 10 == 0:\n",
    "                        train_loss_d = d_loss.eval({input_z: batch_z, input_images: batch_images})\n",
    "                        train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "                        # Save it\n",
    "                        image_name = str(i) + \".jpg\"\n",
    "                        image_path = \"./images/\" + image_name\n",
    "                        show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, True, False) \n",
    "\n",
    "                    # Print every 5 epochs (for stability overwize the jupyter notebook will bug)\n",
    "                    if i % 20 == 0:\n",
    "\n",
    "                        image_name = str(i) + \".jpg\"\n",
    "                        image_path = \"./images/\" + image_name\n",
    "                        print(\"Epoch {}/{}...\".format(epoch_i+1, epochs),\n",
    "                              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                              \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                        show_generator_output(sess, 4, input_z, data_shape[3], data_image_mode, image_path, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size input image for discriminator\n",
    "real_size = (128,128,3)\n",
    "\n",
    "# Size of latent vector to generator\n",
    "z_dim = 100\n",
    "learning_rate_D =  .00005 \n",
    "learning_rate_G = 2e-4 \n",
    "batch_size = 3\n",
    "epochs = 200\n",
    "alpha = 0.2\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vai e crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and train the network here\n",
    "dataset = helper.Dataset(glob(os.path.join(data_resized_dir, '*.jpg')))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate_D, learning_rate_G, beta1, dataset.get_batches,\n",
    "          dataset.shape, dataset.image_mode, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}